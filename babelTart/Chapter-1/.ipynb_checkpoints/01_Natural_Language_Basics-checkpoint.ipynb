{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Natural Language Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 바벨피쉬X싸이그래머 / 바벨타르트 - Part 1 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* Natural Language \n",
    "    - What Is Natural Language? \n",
    "    - The Philosophy of Language\n",
    "    - Language Acquisition and Usage\n",
    "* Linguistics\n",
    "* Language Syntax and Structure \n",
    "    - Words\n",
    "    - Phrases\n",
    "    - Clauses\n",
    "    - Grammar\n",
    "    - Word Order Typology\n",
    "* Language Semantics\n",
    "    - Lexical Semantic Relations\n",
    "    - Semantic Networks and Models\n",
    "    - Representation of Semantics\n",
    "* Text Corpora\n",
    "    - Corpora Annotation and Utilities\n",
    "    - Popular Corpora\n",
    "    - Accessing Text Corpora\n",
    "* Natural Language Processing\n",
    "    - Machine Translation\n",
    "    - Speech Recognition Systems\n",
    "    - Question Answering Systems\n",
    "    - Contextual Recognition and Resolution\n",
    "    - Text Summarization\n",
    "    - Text Categorization\n",
    "* Text Analytics\n",
    "* Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language \n",
    "* What Is Natural Language? \n",
    "* The Philosophy of Language\n",
    "* Language Acquisition and Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is Natural Language? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human languages like English, Japanese, and Sanskrit are natural languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Philosophy of Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The nature of meaning in a language\n",
    "* The use of language\n",
    "* Language cognition\n",
    "* The relationship between language and reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### triangle of reference\n",
    "One of the most popular models is the triangle of reference, which is used to explain how words convey meaning and ideas in the minds of the receiver and how that meaning relates back to a real world entity or fact. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Acquisition and Usage\n",
    "* Language Acquisition and Cognitive Learning\n",
    "* Language Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Acquisition and Cognitive Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Language Acquisition\n",
    "    - In simple terms, the ability of acquiring and producing languages is language acquisition.\n",
    "    - behavioral theory\n",
    "    - Chomsky’s view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 참고 [2] : (위키백과) 언어행위  https://ko.wikipedia.org/wiki/%EC%96%B8%EC%96%B4%ED%96%89%EC%9C%84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will cover some concepts related to speech acts that highlight different ways in which language is used in communication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main categories of speech acts\n",
    "* locutionary acts\n",
    "* illocutionary acts\n",
    "* perlocutionary acts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언어학과 심리철학에서의 언어행위는 발화행위(locutionary act)와 발화수반행위(illocutionary act), 발화효과행위(perlocutionary)의 3가지 하위 행위로 구성된다고 하였다.(utterance). 발화행위란 어떤 문장의 뜻과 지시를 결정하는 행위(선택된 단어,문장구조로 말미암아 일정한 뜻이 있는 것)이다. 발화수반행위란 발화행위에 뒤따라 발생하는 약속,명령,질문,진술,강요 등의 행위를 가리키며, 언어행위의 핵심이다. 발화효과행위란 발화의 결과로 듣는 이를 설득하고, 놀라게 하고, 기쁘게 하고 하는 등의 효과를 나타낸다. 평서문,의문문,명령문은 각각 진술,질문,명령의 발화수반행위와 밀접하게 연관되어 있다. 이러한 문장 유형의 발화로 관련된 발화수반행위를 하는 경우와 그렇지 않은 경우를 구분하기도 한다. (직접화행, 간접화행) 직접화행 대신 간접화행을 쓰는 동기는 공손성(politeness)원리에서 찾기도 한다. 상대방의 체면(face)을 위해 간접화행을 쓰게 된다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The illocutionary act was a directive in this case. According to the philosopher John Searle, there are a total of five different classes of illocutionary speech acts, as follows:\n",
    "* Assertives \n",
    "* Directives\n",
    "* Commisives\n",
    "* Expressives \n",
    "* Declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(구글번역)\n",
    "* 독단이란 세상에 이미 존재하는 것을 전달하는 연설 행위입니다. 그가 시도 할 때 발신자가 말합니다. 현실 세계에서 진실이거나 거짓 일 수있는 명제를 주장하는 것. 이러한 주장은 진술 또는 선언 일 수 있습니다. 간단한 예가 지구가 태양을 공전하는 것입니다. 이 메시지는 이전에 논의 된 단어 - 세계 방향을 나타냅니다.\n",
    "* 지시어는 발신자가 수신자에게 연락하여 무언가를하도록 지시하거나 지시하는 말하기 행위입니다. 이것은 수신자가 보낸 사람의 지시를받은 후에 미래에 할 수있는 자발적인 행위. 지침은 자발적이기 때문에 준수하거나 준수하지 않을 수 있습니다. 이러한 지시문은 간단한 요청 일 수도 있고 명령 또는 명령 일 수도 있습니다. 예제 지시문은 테이블에서 책을 가져와, 이전에 우리가 연설 행위에 대해 이야기했을 때 논의되었습니다.\n",
    "* 커미션은 발신자 또는 연설자가 향후 자발적인 행동이나 행동을 취할 것을 강요하는 연설 행위입니다. 약속, 맹세, 약속 및 서원과 같은 행위는 의사를 대표하며 적합성의 방향은 어느 쪽이든 될 수 있습니다. 예식은 내가 내일 의식에 참석할 것을 약속 할 것입니다.\n",
    "* 표현은 메시지를 통해 전달 된 특정 명제에 대한 발표자 또는 발신자의 성향과 전망을 나타냅니다. 이것들은 축하, 냉소적 인 것과 같은 다양한 형태의 표현이나 감정 일 수 있습니다. 예를 들어 표현하면 클래스를 졸업 한 것을 축하합니다**  *  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고[3] (위키백과) 언어학 - https://ko.wikipedia.org/wiki/%EC%96%B8%EC%96%B4%ED%95%99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Formally, linguistics is defined as the scientific study of language, including form and syntax of language, meaning, and semantics depicted by the usage of language and context of use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트 분석의 경우 언어학에 대한 세부적인 탐구가 필요하지 않지만 자연 언어 처리 및 텍스트 분석 알고리즘에서 광범위하게 사용되기 때문에 언어학의 여러 분야를 아는 것이 유용합니다. 언어학의 주요 연구 분야는 다음과 같습니다.\n",
    "* Phonetics\n",
    "* Phonology\n",
    "* Syntax\n",
    "* Semantics\n",
    "    - Lexical semantics\n",
    "    - Compositional semantics\n",
    "* Morphology\n",
    "* Lexicon\n",
    "* Pragmatics\n",
    "* Discourse analysis\n",
    "* Stylistics\n",
    "* Semiotics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Syntax and Structure \n",
    "* Words\n",
    "* Phrases\n",
    "* Clauses\n",
    "* Grammar\n",
    "* Word Order Typology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고[4] 한글 형태소 품사 (Part Of Speech, POS) 태그표 - http://kkma.snu.ac.kr/documents/?doc=postag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in Chapter 3 we will examining them in further detail and looking at methods of generating POS tags programmatically.\n",
    "Usually, words can fall into one of the following major categories.\n",
    "* N(oun)\n",
    "* V(erb)\n",
    "* Adj(ective)\n",
    "* Adv(erb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고 [5] (위키백과) 구 (언어학)  - https://ko.wikipedia.org/wiki/%EA%B5%AC_(%EC%96%B8%EC%96%B4%ED%95%99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Words have their own lexical properties like parts of speech, which we saw earlier. Using these words, we can order them in ways that give meaning to the words such that each word belongs to a corresponding phrasal category and one of the words is the main or head word. \n",
    "* By principle, phrases are assumed to have at least two or more words, considering the pecking order of words ← phrases ← clauses ← sentences. However, a phrase can be a single word or a combination of words based on the syntax and position of the phrase in a clause or sentence.\n",
    "* There are five major categories of phrases:\n",
    "    - Noun phrase (NP)\n",
    "    - Verb phrase (VP)\n",
    "    - Adjective phrase (ADJP)\n",
    "    - Adverb phrase (ADVP)\n",
    "    - Prepositional phrase (PP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고[6] (위키백과) 절 (언어학) - https://ko.wikipedia.org/wiki/%EC%A0%88_(%EC%96%B8%EC%96%B4%ED%95%99) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By nature, clauses can act as independent sentences, or several clauses can be combined together to form a sentence. A clause is a group of words with some relation between them that usually contains a subject and a predicate. Sometimes the subject is not present, and the predicate usually has a verb phrase or a verb with an object.\n",
    "* With regard to syntactic properties of language, clauses can be subdivided into several categories based on syntax:\n",
    "    - Declarative\n",
    "    - Imperative\n",
    "    - Relative\n",
    "    - Interrogative\n",
    "    - Exclamative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar\n",
    "* Dependency grammars\n",
    "* Constituency Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grammar helps in enabling both syntax and structure in language. It primarily consists of a set of rules used in determining how to position words, phrases, and clauses when constructing sentences for any natural language.\n",
    "* Grammar can be subdivided into two main classes\n",
    "    - dependency grammars and \n",
    "    - constituency grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고[7] Functional Dependency Grammar - https://www.slideshare.net/claudiumihaila/fdg-3736549"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constituency Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.12.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.13.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.15.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Order Typology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typology in linguistics is a field that specifically deals with trying to classify languages based on their syntax, structure, and functionality. Languages can be classified in several ways, and one of the most common models is to classify them according to their dominant word orders, also known as word order typology. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.16.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.17.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Semantics\n",
    "* Lexical Semantic Relations\n",
    "* Semantic Networks and Models\n",
    "* Representation of Semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [8] (KOCW) 국어학개론 12주차. 한국어 의미구조 - http://elearning.kocw.net/KOCW/document/2015/bufs/heoyong/21.pdf\n",
    "* [9] (KOCW) 단어의미론 - http://elearning.kocw.net/KOCW/document/2015/hufs/heoyong/20.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple words, semantics is more concerned with the facial expressions, signs, symbols, body language, and knowledge that are transferred when passing messages from one entity to another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Semantic Relations\n",
    "* Lemmas and Wordforms\n",
    "* Homonyms, Homographs, and Homophones\n",
    "* Heteronyms and Heterographs\n",
    "* Polysemes\n",
    "* Capitonyms\n",
    "* Synonyms and Antonyms\n",
    "* Hyponyms and Hypernyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmas and Wordforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* lemma is also known as the canonical or citation form for a set of words. The lemma is usually the base form of a set of words, known as a lexeme in this context. \n",
    "* Lemma is the specific base form or head word that represents the lexeme. Wordforms are inflected forms of the lemma, which are part of the lexeme and can appear as one of the words from the lexeme in text. \n",
    "* A simple example would the lexeme {eating, ate, eats}, which contains the wordforms, and their lemma is the word eat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homonyms, Homographs, and Homophones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Homonyms (동음 이의어)\n",
    "* Homographs (동형 이의어)\n",
    "* Homophones (동음어)\n",
    "    - Homophones are words that have the same pronunciation but different meanings, and they can have the same or different spellings. Examples would be the words pair (meaning couple) and pear (the fruit). They sound the same but have different meanings and written forms. Often these words cause problems in NLP because it is very difficult to find out the actual context and meaning using machine intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heteronyms and Heterographs\n",
    "* Heteronyms are words that have the same written form or spelling but different pronunciations and meanings. By nature, they are a subset of homographs. They are also often called heterophones, which means “different sound.” Examples of heteronyms are the words lead (metal, command) and tear (rip off something, moisture from eyes).\n",
    "* Heterographs are words that have the same pronunciation but different meanings and spellings. By nature they are a subset of homonyms. Their written representation might be different but they sound very similar or often exactly the same when spoken. Some examples include the words to, too, and two, which sound similar but have different spellings and meanings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polysemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Polysemes are words that have the same written form or spelling and different but very relatable meanings. While this is very similar to homonymy, the difference is subjective and depends on the context, since these words are relatable to each other. \n",
    "* A good example is the word bank which can mean \n",
    "    - (1) a financial institution, \n",
    "    - (2) the bank of the river, \n",
    "    - (3) the building that belongs to the financial institution, or \n",
    "    - (4) a verb meaning to rely upon. \n",
    "    - These examples use the same word bank and are homonyms. But only (1), (3), and (4) are polysemes representing a common theme (the financial organization representing trust and security)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capitonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capitonyms are words that have the same written form or spelling but have different meanings when capitalized. They may or may not have different pronunciations. Some examples include the words march (March indicates the month, and march depicts the action of walking) and may (May indicates the month, and may is a modal verb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonyms and Antonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Synonyms (동의어)\n",
    "* Antonyms (반의어) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyponyms and Hypernyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyponyms (하위어)\n",
    "    - Hyponyms are words that are usually a subclass of another word. In this case, the hyponyms are generally words with very specific sense and context as compared to\n",
    "the word that is their superclass.\n",
    "* Hypernyms (상위어)\n",
    "    - Hypernyms are the words that act as the superclass to hyponyms and have a more generic sense compared to the hyponyms.\n",
    "* An example would be the word fruit, which is a hypernym, and the words mango, orange, and pear would be possible hyponyms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Networks and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.18.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation of Semantics\n",
    "* Propositional Logic\n",
    "* First Order Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [10] Propositional And First-Order Logic - https://www.slideshare.net/ankush_kumar/c10-logic-1\n",
    "* [11] First Order Logic (1차 술어 논리)- http://redcarrot.tistory.com/51\n",
    "* [12] 술어논리 - http://imnt.tistory.com/56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propositional Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.19.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.20.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Order Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.21.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.22.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Corpora\n",
    "* Corpora Annotation and Utilities\n",
    "* Popular Corpora\n",
    "* Accessing Text Corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text corpora is the plural form of text corpus. Text corpora are large and structured collection of texts or textual data, usually consisting of bodies of written or spoken text, often stored in electronic form. This includes converting old historic text corpora from physical to electronic form so that it can be analyzed and processed with ease. The primary purpose of text corpora is to leverage them for linguistic as well as statistical analysis and to use them as data for building NLP tools. Monolingual corpora consist of textual data in only one language, and multilingual corpora consist of textual data in multiple languages.\n",
    "\n",
    "(구글번역)\n",
    "텍스트 코퍼는 복수 형태의 텍스트 코퍼스입니다. 텍스트 자료는 대개 텍스트 형식이나 텍스트 형식의 데이터 모음으로 구성되며 대개 전자 형식으로 저장된 서면 또는 음성 텍스트 본문으로 구성됩니다. 여기에는 오래된 역사적인 텍스트 코로나를 물리적 형식에서 전자 형식으로 변환하여 쉽게 분석하고 처리 할 수 있습니다. 텍스트 코퍼스의 주 목적은 언어 및 통계 분석에 활용하고 NLP 도구를 작성하기위한 데이터로 사용하는 것입니다. 단일 언어 자료는 한 언어로 된 텍스트 데이터로 구성되며, 다국어 자료는 여러 언어로 된 텍스트 데이터로 구성됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpora Annotation and Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고자료\n",
    "* [13] Stemming, Lemmatisation and POS-tagging with Python and NLTK - https://marcobonzanini.com/2015/01/26/stemming-lemmatisation-and-pos-tagging-with-python-and-nltk/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text corpora are annotated with rich metadata, which is extremely useful for getting valuable insights when utilizing the corpora for NLP and text analytics. Popular annotations for text corpora include tagging parts of speech (POS) tags, word stems, lemmas, and many more. Here are some of the most used methods and techniques for annotating text corpora:\n",
    "* POS tagging \n",
    "    - This is mainly used to annotate each word with a POS tag indicating the part of speech associated with it.\n",
    "* Word stems \n",
    "    - A stem for a word is a part of the word to which various affixes can be attached.\n",
    "* Word lemmas\n",
    "    - A lemma is the canonical or base form for a set of words and is also known as the head word.\n",
    "* Dependency grammar\n",
    "    - This includes finding out the various relationships among the components in sentences and annotating the dependencies.\n",
    "* Constituency grammar\n",
    "    - This is used to add syntactic annotation to sentences based on their constituents including phrases and clauses.\n",
    "* Semantic types and roles\n",
    "    - The various constituents of sentences including words and phrases are annotated with specific semantic types and roles, often obtained from an ontology, which indicates what they do. These include things like place, person, time, organization, agent, recipient, theme, and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular Corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Key Word in Context \n",
    "    - KWIC was a methodology invented in the 1860s but used extensively around the 1950s by linguists to index documents and create corpora of concordances.\n",
    "* Brown Corpus\n",
    "    - This was the first million-word corpus for the English language, published by Kucera and Francis in 1961, also known as “A Standard Corpus of Present-Day American English.” This corpus consists of text from a wide variety of sources and categories.\n",
    "* LOB Corpus\n",
    "    - The Lancaster-Oslo-Bergen (LOB) corpus was compiled in the 1970s as a result of collaboration between the University of Lancaster, the University of Oslo, and the Norwegian Computing Centre for the Humanities, Bergen. The main motivation of this project was to provide a British counterpart to the Brown corpus. This corpus is also a million-word corpus consisting of text from a wide variety of sources and categories.\n",
    "* Collins Corpus\n",
    "    - The Collins Birmingham University International Language Database (COBUILD), set up in 1980 at the University of Birmingham and funded by the Collins publishers, built a large electronic corpus of contemporary text in the English language that also paved the way for future corpora like the Bank of English and the Collins COBUILD English Language Dictionary.\n",
    "* CHILDES\n",
    "    - The Child Language Data Exchange System (CHILDES) is a corpus that was created by Brian and Catherine in 1984 that serves as a repository for language acquisition data, including transcripts, audio and video in 26 languages from over 130 different corpora. This has been merged with a larger corpus Talkbank recently. It is used extensively for analyzing the language and speech of young children.\n",
    "* WordNet\n",
    "    - This corpus is a semantic-oriented lexical database for the English language. It was created at Princeton University in 1985 under the supervision of George Armitage. The corpus consists of words and synonym sets (synsets). Besides these, it consists of word definitions, relationships, and examples of using words and synsets. Overall, it is a combination of a dictionary and a thesaurus.\n",
    "* Penn Treebank\n",
    "    - This corpus consists of tagged and parsed English sentences including annotations like POS tags and grammar-based parse trees typically found in treebanks. It can be also defined as a bank of linguistic trees and was created in the University of Pennsylvania, hence the name Penn Treebank.\n",
    "* BNC\n",
    "    - The British National Corpus (BNC) is one of the largest English corpora, consisting of over 100 million words of both written and spoken text samples from a wide variety of sources. This corpus is a representative sample of written and spoken British English of the late 20th century.\n",
    "* ANC\n",
    "    - The American National Corpus (ANC) is a large text corpus in American English that consists of over 22 million words of both spoken and written text samples since the 1990s. It includes data from a wide variety of sources, including emerging sources like email, tweets, and web information not present in the BNC.\n",
    "* COCA\n",
    "    - The Corpus of Contemporary American English (COCA) is the largest text corpus in American English and consists of over 450 million words, including spoken transcripts and written text from various categories and sources.\n",
    "* Google N-gram Corpus\n",
    "    - The Google N-gram Corpus consists of over a trillion words from various sources including books, web pages, and so on. The corpus consists of n-gram files up to 5-grams for each language.\n",
    "* Reuters Corpus\n",
    "    - This corpus is a collection of Reuters news articles and stories released in 2000 specifically for carrying out research in NLP and machine learning.\n",
    "* Web, chat, email, tweets\n",
    "    - These are entirely new forms of text corpora that have sprung up into prominence with the rise of social media. They are obtainable on the Web from various sources including Twitter, Facebook, chat rooms, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Text Corpora\n",
    "* Accessing the Brown Corpus\n",
    "* Accessing the Reuters Corpus¶\n",
    "* Accessing the WordNet Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/moodern/anaconda/envs/babeltart/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: six in /Users/moodern/anaconda/envs/babeltart/lib/python3.6/site-packages (from nltk)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package qc to /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package hmm_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/hmm_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/moodern/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the Brown Corpus\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Categories: 15\n"
     ]
    }
   ],
   "source": [
    "print('Total Categories:', len(brown.categories()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "print(brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['There', 'were', 'thirty-eight', 'patients', 'on', 'the', 'bus', 'the', 'morning', 'I', 'left', 'for', 'Hanover', ',', 'most', 'of', 'them', 'disturbed', 'and', 'hallucinating', '.'], ['An', 'interne', ',', 'a', 'nurse', 'and', 'two', 'attendants', 'were', 'in', 'charge', 'of', 'us', '.'], ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized sentences\n",
    "brown.sents(categories='mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('There', 'EX'), ('were', 'BED'), ('thirty-eight', 'CD'), ('patients', 'NNS'), ('on', 'IN'), ('the', 'AT'), ('bus', 'NN'), ('the', 'AT'), ('morning', 'NN'), ('I', 'PPSS'), ('left', 'VBD'), ('for', 'IN'), ('Hanover', 'NP'), (',', ','), ('most', 'AP'), ('of', 'IN'), ('them', 'PPO'), ('disturbed', 'VBN'), ('and', 'CC'), ('hallucinating', 'VBG'), ('.', '.')], [('An', 'AT'), ('interne', 'NN'), (',', ','), ('a', 'AT'), ('nurse', 'NN'), ('and', 'CC'), ('two', 'CD'), ('attendants', 'NNS'), ('were', 'BED'), ('in', 'IN'), ('charge', 'NN'), ('of', 'IN'), ('us', 'PPO'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tagged sentences\n",
    "brown.tagged_sents(categories='mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get sentences in natural form\n",
    "sentences = brown.sents(categories='mystery')\n",
    "sentences = [' '.join(sentence_token) for sentence_token in\n",
    "sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There were thirty-eight patients on the bus the morning I left for Hanover , most of them disturbed and hallucinating .', 'An interne , a nurse and two attendants were in charge of us .', \"I felt lonely and depressed as I stared out the bus window at Chicago's grim , dirty West Side .\", 'It seemed incredible , as I listened to the monotonous drone of voices and smelled the fetid odors coming from the patients , that technically I was a ward of the state of Illinois , going to a hospital for the mentally ill .', 'I suddenly thought of Mary Jane Brennan , the way her pretty eyes could flash with anger , her quiet competence , the gentleness and sweetness that lay just beneath the surface of her defenses .']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0:5]) # printing first 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get tagged words\n",
    "tagged_words = brown.tagged_words(categories='mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get nouns from tagged words\n",
    "nouns = [(word, tag) for word, tag in tagged_words \n",
    "         if any(noun_tag in tag for noun_tag in ['NP', 'NN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('patients', 'NNS'), ('bus', 'NN'), ('morning', 'NN'), ('Hanover', 'NP'), ('interne', 'NN'), ('nurse', 'NN'), ('attendants', 'NNS'), ('charge', 'NN'), ('bus', 'NN'), ('window', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(nouns[0:10]) # prints the first 10 nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build frequency distribution for nouns\n",
    "nouns_freq = nltk.FreqDist([word for word, tag in nouns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('man', 106), ('time', 82), ('door', 80), ('car', 69), ('room', 65), ('Mr.', 63), ('way', 61), ('office', 50), ('eyes', 48), ('hand', 46)]\n"
     ]
    }
   ],
   "source": [
    "# print top 10 occuring nouns\n",
    "print(nouns_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Reuters Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the Reuters Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Total Categories ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get sentences in housing and income categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prints the first 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fileid based access - 'housing', 'income'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the WordNet Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the Wordnet Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# taking hike as our word of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get word synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get details for each synonym in synset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "* Machine Translation\n",
    "* Speech Recognition Systems\n",
    "* Question Answering Systems\n",
    "* Contextual Recognition and Resolution\n",
    "* Text Summarization\n",
    "* Text Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I’ve mentioned the term natural language processing (NLP) several times in this chapter. By now, you may have formed some idea about what NLP means. NLP is defined as a specialized field of computer science and engineering and artificial intelligence with roots in computational linguistics. It is primarily concerned with designing and building applications and systems that enable interaction between machines and natural languages evolved for use by humans. This also makes NLP related to the area of Human-Computer Interaction (HCI). NLP techniques enable computers to process and understand natural human language and utilize it further to provide useful output. Next, we will be talking about some of the main applications of NLP.\n",
    "\n",
    "(구글 번역) 이 장에서는 자연어 처리 (NLP)라는 용어를 여러 번 언급했습니다. 지금까지 NLP가 무엇을 의미하는지에 대한 아이디어를 얻었을 것입니다. NLP는 다음과 같이 정의됩니다. 컴퓨터 공학 및 인공 지능 전문 분야 전산 언어학에 뿌리를두고 있습니다. 이것은 주로 기계와 인간이 사용하기 위해 진화 된 자연어 간의 상호 작용을 가능하게하는 응용 프로그램 및 시스템을 설계하고 구축하는 데 관련됩니다. 이로 인해 NLP는 HCI (Human-Computer Interaction) 영역과 관련됩니다. NLP 기술은 컴퓨터가 자연 언어를 처리하고 이해할 수있게하고 유용한 출력을 제공하기 위해 컴퓨터를 활용합니다. 다음으로, 우리는 NLP의 주요 응용 프로그램에 대해 이야기 할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig1.23.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual Recognition and Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As mentioned before, with the advent of huge amounts of computing power, unstructured data, and success with machine learning and statistical analysis techniques, it wasn’t long before text analytics started garnering a lot of attention. However, text analytics poses some challenges compared to regular analytical methods. Free-flowing text is highly unstructured and rarely follows any specific pattern—like weather data or structured attributes in relational databases. Hence, standard statistical methods aren’t helpful when applied out of the box on unstructured text data. This section covers some of the main concepts in text analytics and also discusses the definition and scope of text analytics, which will give you a broad idea of what you can expect in the upcoming chapters.\n",
    "\n",
    "(구글 번역) 앞서 언급했듯이 컴퓨팅 파워, 구조화되지 않은 데이터 및 기계 학습 및 통계 분석 기술의 성공으로 막대한 양의 텍스트 분석이 집중되기 시작한 것은 오래되었습니다. 그러나 텍스트 분석은 일반적인 분석 방법에 비해 몇 가지 문제점을 제기합니다. 자유로운 텍스트는 고도로 구조화되어 있지 않으며 관계형 데이터베이스의 특정 패턴과 유사한 날씨 데이터 나 구조화 된 속성을 거의 따르지 않습니다. 따라서 표준 통계 방법은 구조화되지 않은 텍스트 데이터에 즉시 적용 할 때 도움이되지 않습니다. 이 섹션에서는 텍스트 분석의 주요 개념을 다루고 텍스트 분석의 정의와 범위에 대해서도 설명합니다. 텍스트 분석은 다음 장에서 기대할 수있는 것을 폭넓게 제공합니다.\n",
    "\n",
    "* Text analytics, also known as text mining, is the methodology and process followed to derive quality and actionable information and insights from textual data. This involves using NLP, information retrieval, and machine learning techniques to parse unstructured text data into more structured forms and deriving patterns and insights from this data that would be helpful for the end user. Text analytics comprises a collection of machine learning, linguistic, and statistical techniques that are used to model and extract information from text primarily for analysis needs, including business intelligence, exploratory, descriptive, and predictive analysis. Here are some of the main techniques and operations in text analytics:\n",
    "    - Text classification\n",
    "    - Text clustering\n",
    "    - Text summarization\n",
    "    - Sentiment analysis\n",
    "    - Entity extraction and recognition\n",
    "    - Similarity analysis and relation modeling\n",
    "\n",
    "(구글번역) 텍스트 마이닝이라고도하는 텍스트 분석은 텍스트 데이터에서 품질 및 실행 가능한 정보와 통찰력을 이끌어내는 방법론 및 프로세스입니다. 여기에는 NLP, 정보 검색 및 기계 학습 기술을 사용하여 구조화되지 않은 텍스트 데이터를보다 구조화 된 형식으로 구문 분석하고 최종 사용자에게 도움이 될이 데이터에서 패턴과 통찰력을 유도합니다. 텍스트 분석은 주로 비즈니스 인텔리전스, 탐색, 설명 및 예측 분석을 포함하여 분석 요구에 맞게 텍스트에서 정보를 모델링하고 추출하는 데 사용되는 기계 학습, 언어 및 통계 기술 모음입니다. 다음은 텍스트 분석의 주요 기술 및 작업입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Once we have the data in a machine-readable and understandable format, we can apply relevant algorithms based on the problem to be solved at hand. The applications of text analytics are manifold. Some of the most popular ones include the following:\n",
    "    - Spam detection\n",
    "    - News articles categorization\n",
    "    - Social media analysis and monitoring\n",
    "    - Bio-medical\n",
    "    - Security intelligence\n",
    "    - Marketing and CRM\n",
    "    - Sentiment analysis\n",
    "    - Ad placements\n",
    "    - Chatbots\n",
    "    - Virtual assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (특별) 실습\n",
    "* 참고[14] 파이썬으로 영어와 한국어 텍스트 다루기 - https://www.lucypark.kr/courses/2015-dm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 해봅시다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료 \n",
    "* [1] Text Analytics with Python: A Practical Real-World Approach to Gaining Actionable Insights from your Data \n",
    "* [2] (위키백과) 언어행위 - https://www.amazon.com/Text-Analytics-Python-Real-World-Actionable/dp/148422387X https://ko.wikipedia.org/wiki/%EC%96%B8%EC%96%B4%ED%96%89%EC%9C%84\n",
    "* [3] (위키백과) 언어학 - https://ko.wikipedia.org/wiki/%EC%96%B8%EC%96%B4%ED%95%99\n",
    "* [4] 한글 형태소 품사 (Part Of Speech, POS) 태그표 - http://kkma.snu.ac.kr/documents/?doc=postag\n",
    "* [5] (위키백과) 구 (언어학)  - https://ko.wikipedia.org/wiki/%EA%B5%AC_(%EC%96%B8%EC%96%B4%ED%95%99)\n",
    "* [6] (위키백과) 절 (언어학) - https://ko.wikipedia.org/wiki/%EC%A0%88_(%EC%96%B8%EC%96%B4%ED%95%99)\n",
    "* [7] Functional Dependency Grammar - https://www.slideshare.net/claudiumihaila/fdg-3736549\n",
    "* [8] (KOCW) 국어학개론 12주차. 한국어 의미구조 - http://elearning.kocw.net/KOCW/document/2015/bufs/heoyong/21.pdf\n",
    "* [9] (KOCW) 단어의미론 - http://elearning.kocw.net/KOCW/document/2015/hufs/heoyong/20.pdf\n",
    "* [10] Propositional And First-Order Logic - https://www.slideshare.net/ankush_kumar/c10-logic-1\n",
    "* [11] First Order Logic (1차 술어 논리)- http://redcarrot.tistory.com/51\n",
    "* [12] 술어논리 - http://imnt.tistory.com/56\n",
    "* [13] Stemming, Lemmatisation and POS-tagging with Python and NLTK - https://marcobonzanini.com/2015/01/26/stemming-lemmatisation-and-pos-tagging-with-python-and-nltk/\n",
    "* [14] 파이썬으로 영어와 한국어 텍스트 다루기 - https://www.lucypark.kr/courses/2015-dm/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
